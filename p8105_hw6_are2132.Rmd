---
title: "P8105 Homework 6"
author: "Alison Elgass"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
set.seed(1)
```

# Problem 1
First load and tidy birth weight data.  
Note that the Children's Hospital of Philadelphia defines low birth weight as less than 2500 grams (5 lbs 8 oz).
```{r}
bwt_data = read_csv(file = "./data/birthweight.csv") %>% 
  mutate(
    babysex = factor(babysex, levels = c(1,2), 
                     labels = c("male","female")),
    frace = factor(frace, levels = c(1,2,3,4,8,9), 
                   labels = c("white","black","asian","puerto rican",
                              "other","unknown")),
    malform = factor(malform, levels = c(0,1), 
                     labels = c("absent","present")),
    mrace = factor(mrace, levels = c(1,2,3,4,8,9), 
                   labels = c("white","black","asian","puerto rican",
                              "other","unknown"))
  )

map(bwt_data, ~sum(is.na(.))) #check for missing values

```

## My Regression Model
I hypothesize these factors may impact baby birthweight:  

* Baby length
* Gestational age
* Presence of malformations
* Number of previous live births
* Mom's pre-pregnancy BMI
* Cigarettes smoked during pregnancy  

I start with a linear regression using these as covariates.
```{r}
lr1 = lm(bwt ~ blength + gaweeks + malform + parity + ppbmi + smoken,
         data = bwt_data)
lr1 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 2)

bwt_data %>% 
  count(malform) %>% 
  knitr::kable()
```

It appears as though the malformations covariate is not significant. Upon further exploration we see that only 15 subjects have this malformation marked as present. Due to the small sample size I'll leave it out of the model. The rest remains the same.  
  
Our new model is:
```{r}
lr2 = lm(bwt ~ blength + gaweeks + parity + ppbmi + smoken,
         data = bwt_data)
summary(lr2)
```

### Model Diagnostics
```{r}
#add residuals and predictions (fitted bwt values)
bwt_diagnostics = bwt_data %>% 
  modelr::add_residuals(lr2) %>% 
  modelr::add_predictions(lr2)

#plot residuals vs. predictions
bwt_diagnostics %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_vline(xintercept = 2500, size = 1, color = "red") +
  ylim(-1000, 1000) + xlim(2000, 4000) +
  ggtitle("Residuals vs. Predicted Bwt Values")
```

The red vertical line represents the defined cutoff for low birthweight (< 2500 grams).  

## Comparing to Other Models
We compare this model to the following models  
1. One using length at birth and gestational age as predictors (main effects only)  
2. One using head circumference, length, sex, and all interactions (including the three-way interaction) between these  
    
Now we use cross validation to compare these models!
```{r}
cv_data = 
  crossv_mc(bwt_data, 100)

cv_data = 
  cv_data %>% 
  mutate(my_mod  = map(train, ~lm(bwt ~ blength + gaweeks + parity + 
                                    ppbmi + smoken, data = .x)),
         mod1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         mod2  = map(train, ~lm(bwt ~ bhead + blength + babysex + 
            bhead*blength + bhead*babysex + blength*babysex +
            bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_mine = map2_dbl(my_mod, test, 
                                ~rmse(model = .x, data = .y)),
         rmse_mod1 = map2_dbl(mod1, test, 
                                ~rmse(model = .x, data = .y)),
         rmse_mod2 = map2_dbl(mod2, test, 
                                ~rmse(model = .x, data = .y)))

cv_data %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

It looks like model 2 is definitely the best with the lowest distribution of prediction errors.  


# Problem 2
First load in weather data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Next take 5,000 bootstrap samples from weather data
```{r}
big_boot = 
  weather_df %>% 
  modelr::bootstrap(n = 5000)

#names(big_boot)
#as_data_frame(big_boot$strap[[1]])
```

Then we use map to take a linear regression of each bootstrap sample, use broom::tidy and glance to get the summary stats, and mutate/wrangle/pivot the giant dataframe of values to end up with the desired statistics, r^2^ and log(b~0~ * b~1~)
```{r}
# (not the most descriptive variable name, 
# but can't not make the spongebob reference)
bigger_boot = big_boot %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    glances = map(models, broom::glance),
    tidies = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(c(glances, tidies), names_repair = "universal") %>% 
  pivot_wider(  #outputs b0, b1, r2
    names_from = term,          #intercept (b0) & estimate (b1)
    names_repair = "universal", #removes () around intercept name
    values_from = estimate, r.squared) %>% 
  mutate(
    logbb = log(.Intercept.*tmin)
  )

head(bigger_boot)
```

Now plot the distributions
```{r}
ggplot(bigger_boot, aes(x = r.squared)) + 
  geom_histogram() + ggtitle("R^2 for 5,000 bootstraps")

ggplot(bigger_boot, aes(x = logbb)) + 
  geom_histogram() + ggtitle("Log(b0*b1) for 5,000 bootstraps")
```

Both distributions are approximately normal. The peak of the distribution/median r^2^ appears to be just over 0.91, indicating that the model fits well. r^2^ = 0.91 would mean that about 91% of the variation in tmax can be explained by tmin.  
  
The median for log(b~0~ * b~1~) appears to be around 2.02.

## Quantiles & Confidence Intervals
```{r}
ordered_r2 = bigger_boot %>% 
  arrange(r.squared)

r2_lower = pull(ordered_r2, r.squared)[125]  #2.5 percentile
r2_upper = pull(ordered_r2, r.squared)[4875] #97.5 percentile

ordered_logbb = bigger_boot %>% 
  arrange(logbb)

bb_lower = pull(ordered_logbb, logbb)[125]  #2.5 percentile
bb_upper = pull(ordered_logbb, logbb)[4875] #97.5 percentile
```

Extracting the 2.5 and 97.5% quantiles from our list of 5,000 bootstrap samples, we end up with the following confidence intervals:  
  
95% CI for r^2^ = (`r round(r2_lower, 3)`, `r round(r2_upper,3)`)  
95% CI for log(b~0~ * b~1~) = (`r round(bb_lower,3)`, `r round(bb_upper,3)`)
